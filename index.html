<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ishan Ahluwalia</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="container">
        <nav>
            <a href="#home">Home</a>
            <a href="#research">Research</a>
            <a href="#projects">Projects</a>
            <a href="#experience">Experience</a>
        </nav>

        <section id="home">
            <h1>Ishan Ahluwalia</h1>
            <p class="subtitle">AI & Applied Mathematics | University of Pennsylvania</p>
            <p class="bio">I develop intelligent systems that bridge robotics and artificial intelligence. My work focuses on brain-computer interfaces, reinforcement learning for robotic control, and movement prediction systems for assistive technologies.</p>
            
            <div class="contact">
                <p>ishanah@seas.upenn.edu</p>
                <p><a href="https://www.linkedin.com/in/ishan-ahluwalia-ahlu/">LinkedIn</a> | <a href="https://github.com/IshanAhluwalia">GitHub</a></p>
            </div>
        </section>

        <section id="research">
            <h2>Research</h2>
            
            <div class="research-item">
                <h3>SUNG Robotics Lab, GRASP Lab, University of Pennsylvania</h3>
                <p class="position">Robotics Researcher | Aug 2025 – Present</p>
                <ul class="research-bullets">
                    <li>Developing reinforcement learning control algorithms for aquatic robots using reward states and Markov Decision Processes</li>
                    <li>Installing DenseTack Mini 2 tactile sensors for enhanced underwater perception and companion robot location mapping</li>
                    <li>Building CNN architectures for real-time location mapping in aquatic environments</li>
                    <li>Contributing to computational co-design approaches for adaptive robotic platforms</li>
                    <li>Working on underwater locomotion and distributed robotic systems research</li>
                </ul>
                <p><strong>Lab Website:</strong> <a href="https://sung.seas.upenn.edu/" target="_blank">sung.seas.upenn.edu</a></p>
            </div>

            <div class="research-item">
                <h3>LDOS Lab, University of Pennsylvania</h3>
                <p class="position">OS/AI Researcher | Jan 2025 – Sep 2025</p>
                <ul class="research-bullets">
                    <li>Contributing to Learning Directed Operating System project replacing manual OS heuristics with ML-based resource management</li>
                    <li>Profiled allocative slow-path bottlenecks across page compaction routines using kyprobes and custom benchmarking</li>
                    <li>Analyzed 127K+ lines of Linux kernel (mm/compaction.c) for memory optimization opportunities</li>
                    <li>Designed and implemented recursive data management algorithms for memory fragmentation optimization</li>
                    <li>Achieved ~18% improvement in memory throughput on synthetic workloads</li>
                    <li>Supporting development of self-adaptive operating systems for real-time applications and edge computing</li>
                </ul>
                <p><strong>Lab Website:</strong> <a href="https://ldos.utexas.edu/about" target="_blank">ldos.utexas.edu</a></p>
            </div>

        </section>

        <section id="projects">
            <h2>Projects</h2>

            <div class="project featured horizontal">
                <div class="project-content">
                    <h3>NeuroMotus: Brain-Computer Interface for Cerebral Palsy</h3>
                    <p class="position">Independent Research | 2020 – 2024</p>
                    <p>Developed a novel intent-based movement prediction system using EEG signals to optimize exoskeletons for Cerebral Palsy patients. Built CNN architecture achieving 94% accuracy in detecting movement intent from Bereitschaftspotential signals. System predicts 6 essential movements with 87% accuracy, expanding exoskeleton capabilities beyond basic walking patterns.</p>
                    <p><strong>Recognition:</strong> 2nd Place Grand Award & CIA Award, ISEF 2023</p>
                </div>
                
                <div class="project-materials">
                    <div class="media-container">
                        <div class="project-image">
                            <img src="neuromotus-cap.png" alt="NeuroMotus EEG Cap System" />
                            <p class="image-caption">Custom EEG cap with OpenBCI Cyton board</p>
                        </div>
                        
                        <div class="project-video">
                            <video controls width="300">
                                <source src="neuromotus-demo.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="image-caption">Live Demo - NWSE 2023</p>
                        </div>
                    </div>
                    
                    <div class="project-links">
                        <a href="neuromotus-poster.pdf">Research Poster</a>
                        <a href="neuromotus-paper.pdf">Research Paper</a>
                        <a href="neuromotus-demo.mp4">Download Demo</a>
                    </div>
                </div>
            </div>

            <div class="project featured horizontal">
                <div class="project-content">
                    <h3>RoboSuite Door Opening</h3>
                    <p class="position">Reinforcement Learning Project | May 2025 – Present</p>
                    <p>Built DDPG actor-critic reinforcement learning system for robotic door manipulation using PyTorch and MuJoCo simulation environment. Implemented tanh actor network (256→128 layers) and Q-critic with experience replay buffer, Gaussian noise exploration, and soft target updates (τ=0.005).</p>
                    <p><strong>Technical Details:</strong> Used Adam/AdamW optimizers with learning rate 1e-3 and custom reward shaping to guide the Panda robot arm through complex door opening sequences. System learns to handle door handle grasping, turning, and pulling motions.</p>
                    <p><strong>Results:</strong> Achieved 98% success rate with mean episodic return improving from 90 at initialization to 230 by 7k training steps under fixed seeds and identical evaluation protocol.</p>
                </div>
                
                <div class="project-materials">
                    <div class="media-container">
                        <div class="project-image">
                            <img src="robosuite-learning-curve.png" alt="RoboSuite Door Opening Learning Curve" />
                            <p class="image-caption">Training Progress: Episodic Return vs Training Steps</p>
                        </div>
                        
                        <div class="project-video">
                            <video controls width="300">
                                <source src="robosuite-door.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video>
                            <p class="image-caption">DDPG Agent Learning Door Opening Task</p>
                        </div>
                    </div>
                    
                    <div class="project-links">
                        <a href="https://github.com/IshanAhluwalia/RLforRoboticDoor" target="_blank">GitHub Code</a>
                        <a href="robosuite-door.mp4">Download Demo</a>
                    </div>
                </div>
            </div>

        </section>

        <section id="experience">
            <h2>Experience</h2>

            <div class="timeline">
                <div class="timeline-item">
                    <div class="timeline-date">Jan 2025 - Sep 2025</div>
                    <div class="timeline-content">
                        <h3>MediVoice AI</h3>
                        <p class="position">Software Engineering Intern</p>
                        <p>Built scalable web scraping pipeline generating 100K+ medical QA pairs using Python and BeautifulSoup. Integrated real-time ASR pipelines using Whisper + VOSK for patient-doctor speech transcription.</p>
                    </div>
                </div>

                <div class="timeline-item">
                    <div class="timeline-date">Apr 2023 – Aug 2024</div>
                    <div class="timeline-content">
                        <h3>Oregon Health & Science University</h3>
                        <p class="position">Robotics Systems Engineer Intern</p>
                        <p>Built custom CNN architecture for decoding Bereitschaftspotential EEG signals, achieving 23.3% faster response time for virtual hand simulations. Engineered bidirectional neurofeedback loop between EEG input and ROS-controlled limb simulator.</p>
                    </div>
                </div>

                <div class="timeline-item">
                    <div class="timeline-date">Dec 2021 – Jun 2023</div>
                    <div class="timeline-content">
                        <h3>Biomotum Inc</h3>
                        <p class="position">Software & Mechanical Engineering Intern</p>
                        <p>Developed Python-based calibration algorithms for exoskeletal prosthetics using SVD and PCA. Proposed CAD modifications to Spark prosthetic system improving energy efficiency and wearability.</p>
                    </div>
                </div>
            </div>
        </section>

        <footer>
            <p>Last updated: October 2024</p>
        </footer>
    </div>
</body>
</html>